{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vision2021-ex05c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/Vision/blob/main/Vision2021_ex05c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i23soYCe-ftk"
      },
      "source": [
        "# Vision2021-ex05c\n",
        "\n",
        "課題の期限や提出の方法などについては，Visionチーム内に書いてます．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI3mY1FGZWgV"
      },
      "source": [
        "# ニューラルネットやってみよう\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2ajEMYLWlhT"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E13UrMaqWnFB"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxu3xUj4xN0j"
      },
      "source": [
        "## MNIST の入手"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ud7o6oByPWH"
      },
      "source": [
        "MNIST についてはこちらを参考: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MllQgpMUyBJT"
      },
      "source": [
        "# 上記サイトから 4 つのファイルを入手し， gunzip\n",
        "! for fn in train-images-idx3-ubyte t10k-images-idx3-ubyte train-labels-idx1-ubyte t10k-labels-idx1-ubyte; do if [ ! -e ${fn} ]; then wget -nc http://yann.lecun.com/exdb/mnist/${fn}.gz ; gunzip ${fn}.gz; fi; done\n",
        "! ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfQ7x5ws0Tmz"
      },
      "source": [
        "## MNIST を扱う関数の定義と動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oITH_eAnxMsb"
      },
      "source": [
        "# MNIST のためのクラスの定義\n",
        "\n",
        "import struct\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class MNIST:\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        fnImageL = 'train-images-idx3-ubyte'\n",
        "        fnImageT = 't10k-images-idx3-ubyte'\n",
        "        fnLabelL = 'train-labels-idx1-ubyte'\n",
        "        fnLabelT = 't10k-labels-idx1-ubyte'\n",
        "    \n",
        "        if not os.path.exists(fnImageL) or not os.path.exists(fnImageT) or not os.path.exists(fnLabelL) or not os.path.exists(fnLabelT):\n",
        "            print('Please get the MNIST files first.')\n",
        "            return\n",
        "       \n",
        "        self.fnImage = {'L': fnImageL, 'T': fnImageT}\n",
        "        self.fnLabel  = {'L': fnLabelL, 'T': fnLabelT}\n",
        "        self.nrow = 28\n",
        "        self.ncol = 28\n",
        "        self.nclass = 10\n",
        "        \n",
        "        \n",
        "    def getLabel( self, LT ):\n",
        "        \n",
        "        return _readLabel( self.fnLabel[LT] )\n",
        " \n",
        " \n",
        "    def getImage( self, LT ):\n",
        "        \n",
        "        return _readImage( self.fnImage[LT] )\n",
        " \n",
        " \n",
        "##### reading the label file\n",
        "#\n",
        "def _readLabel( fnLabel ):\n",
        " \n",
        "    f = open( fnLabel, 'rb' )\n",
        " \n",
        "    ### header (two 4B integers, magic number(2049) & number of items)\n",
        "    #\n",
        "    header = f.read( 8 )\n",
        "    mn, num = struct.unpack( '>2i', header )  # MSB first (bigendian)\n",
        "    assert mn == 2049\n",
        "    #print mn, num\n",
        " \n",
        "    ### labels (unsigned byte)\n",
        "    #\n",
        "    label = np.array( struct.unpack( '>%dB' % num, f.read() ), dtype = int )\n",
        " \n",
        "    f.close()\n",
        " \n",
        "    return label\n",
        "\n",
        " \n",
        "##### reading the image file\n",
        "#\n",
        "def _readImage( fnImage ):\n",
        " \n",
        "    f = open( fnImage, 'rb' )\n",
        " \n",
        "    ### header (four 4B integers, magic number(2051), #images, #rows, and #cols\n",
        "    #\n",
        "    header = f.read( 16 )\n",
        "    mn, num, nrow, ncol = struct.unpack( '>4i', header ) # MSB first (bigendian)\n",
        "    assert mn == 2051\n",
        "    #print mn, num, nrow, ncol\n",
        " \n",
        "    ### pixels (unsigned byte)\n",
        "    #\n",
        "    npixel = ncol * nrow\n",
        "    #pixel = np.empty( ( num, npixel ), dtype = int )\n",
        "    #pixel = np.empty( ( num, npixel ), dtype = np.int32 )\n",
        "    pixel = np.empty( ( num, npixel ) )\n",
        "    for i in range( num ):\n",
        "        buf = struct.unpack( '>%dB' % npixel, f.read( npixel ) )\n",
        "        pixel[i, :] = np.asarray( buf )\n",
        " \n",
        "    f.close()\n",
        " \n",
        "    return pixel\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfp_79-y1f_D"
      },
      "source": [
        "### MNIST クラスの動作確認 ###\n",
        "\n",
        "mnist = MNIST()\n",
        "print(mnist.nrow, mnist.ncol, mnist.nclass)\n",
        "\n",
        "print( '# MNIST training data' )\n",
        "dat = mnist.getImage( 'L' )\n",
        "lab = mnist.getLabel( 'L' )\n",
        "print( dat.shape, dat.dtype, lab.shape, lab.dtype )\n",
        " \n",
        "print( '# MNIST test data' )\n",
        "dat = mnist.getImage( 'T' )\n",
        "lab = mnist.getLabel( 'T' )\n",
        "print( dat.shape, dat.dtype, lab.shape, lab.dtype )    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEvg1qQAFA2h"
      },
      "source": [
        "### mini batch indicies for stochastic gradient ascent\n",
        "#\n",
        "def makeBatchIndex(N, batchsize):\n",
        "\n",
        "    idx = np.random.permutation(N)\n",
        "        \n",
        "    nbatch = int(np.ceil(float(N) / batchsize))\n",
        "    idxB = np.zeros(( nbatch, N ), dtype = bool)\n",
        "    for ib in range(nbatch - 1):\n",
        "        idxB[ib, idx[ib*batchsize:(ib+1)*batchsize]] = True\n",
        "    ib = nbatch - 1\n",
        "    idxB[ib, idx[ib*batchsize:]] = True\n",
        "\n",
        "    return idxB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD2-Ck8eo63s"
      },
      "source": [
        "## ネットワークの定義（階層型ニューラルネットワーク）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWhz5EjiTNsy"
      },
      "source": [
        "# 深層学習ライブラリ PyTorch 関係の import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# ネットワークのアーキテクチャを定義するクラス NN \n",
        "\n",
        "class NN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(NN, self).__init__()\n",
        "        \n",
        "        self.isMLP2 = True\n",
        "        \n",
        "        if self.isMLP2:\n",
        "            ### MLP2: 入力 - 中間層 - 出力層\n",
        "            self.fc1 = nn.Linear(784, 256)   # 入力次元数, 中間層ニューロン数\n",
        "            self.fc2 = nn.Linear(self.fc1.out_features, 10)  # 出力層ニューロン数\n",
        "        else:\n",
        "            ### MLP3: 入力 - 中間層1 - 中間層2 - 出力層\n",
        "            self.fc1 = nn.Linear(784, 1024)   # 入力次元数, 中間層ニューロン数\n",
        "            self.fc2 = nn.Linear(self.fc1.out_features, 256)\n",
        "            self.fc3 = nn.Linear(self.fc2.out_features, 10)  # 出力層ニューロン数\n",
        "            \n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        if self.isMLP2:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = self.fc2(X)\n",
        "        else:\n",
        "            X = F.relu(self.fc1(X))\n",
        "            X = F.relu(self.fc2(X))\n",
        "            X = self.fc3(X)\n",
        "        \n",
        "        \n",
        "        return F.log_softmax(X, dim = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yYoS50bci_n"
      },
      "source": [
        "# データを与えると損失関数（交差エントロピー）の値と識別率を計算する関数\n",
        "\n",
        "def evaluate(model, X, Y, bindex):\n",
        "\n",
        "    nbatch = bindex.shape[0]\n",
        "    loss = 0\n",
        "    ncorrect = 0\n",
        "    with torch.no_grad():\n",
        "        for ib in range(nbatch):\n",
        "            ii = np.where(bindex[ib, :])[0]\n",
        "            output = model(X[ii, ::])\n",
        "            #loss += F.nll_loss(output, Y[ii], size_average=False).item()\n",
        "            loss += F.nll_loss(output, Y[ii], reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1] # argmax of the output\n",
        "            ncorrect += pred.eq(Y[ii].view_as(pred)).sum().item()\n",
        "\n",
        "    loss /= X.shape[0]\n",
        "    acc = ncorrect / X.shape[0]\n",
        "\n",
        "    return loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlT7EveGGVB7"
      },
      "source": [
        "# CUDA （NVIDIAのGPGPUライブラリ） が使えるかチェック\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print('# using', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1V60DWgrrz7"
      },
      "source": [
        "## 学習データの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ060U1iIzZG"
      },
      "source": [
        "# 学習データと検査データ\n",
        "\n",
        "mn = MNIST()\n",
        "D = mn.nrow * mn.ncol\n",
        "K = mn.nclass\n",
        "\n",
        "datLraw = mn.getImage('L') / 255.0  #  [0, 255] => [0,1]\n",
        "labLraw = mn.getLabel('L')\n",
        "datL = datLraw[:50000, :]   # 6万個のうち最初の5万個を学習用に\n",
        "labL = labLraw[:50000]\n",
        "datV = datLraw[50000:, :]   # 残りは検査(validation)用に\n",
        "labV = labLraw[50000:]\n",
        "\n",
        "NL = datL.shape[0]\n",
        "NV = datV.shape[0]\n",
        "\n",
        "### to torch.Tensor\n",
        "#\n",
        "XL = torch.from_numpy(datL.astype(np.float32)).to(device)\n",
        "YL = torch.from_numpy(labL).to(device)\n",
        "XV = torch.from_numpy(datV.astype(np.float32)).to(device)\n",
        "YV = torch.from_numpy(labV).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11KPE_K9swor"
      },
      "source": [
        "## 学習させる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWrCdKiKHJpy"
      },
      "source": [
        "%%time\n",
        "\n",
        "### initializing the network\n",
        "#\n",
        "torch.manual_seed(0)\n",
        "net = NN()\n",
        "model = net.to(device)\n",
        "print(model)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
        "print(optimizer)\n",
        "\n",
        "### training\n",
        "#\n",
        "batchsize = 128\n",
        "bindexL = makeBatchIndex(NL, batchsize)\n",
        "nbatchL = bindexL.shape[0]\n",
        "bindexV = makeBatchIndex(NV, batchsize)\n",
        "nbatchV = bindexV.shape[0]\n",
        "\n",
        "nitr = 10000\n",
        "nd = 0\n",
        "    \n",
        "for i in range(nitr):\n",
        "\n",
        "    if (i < 500 and i % 100 == 0) or (i % 500 == 0):\n",
        "            \n",
        "        model.eval()  # setting the module in evaluation mode\n",
        "        lossL, accL = evaluate(model, XL, YL, bindexL)\n",
        "        lossV, accV = evaluate(model, XV, YV, bindexV)\n",
        "        print(i, nd, end = '     ')\n",
        "        print('{:.4f} {:.2f}'.format(lossL, accL*100), end = '     ') \n",
        "        print('{:.4f} {:.2f}'.format(lossV, accV*100), end = '     ') \n",
        "        print()\n",
        "            \n",
        "             \n",
        "    model.train()  # setting the module in training mode\n",
        "    ib = np.random.randint(0, nbatchL)\n",
        "    ii = np.where(bindexL[ib, :])[0]\n",
        "    optimizer.zero_grad()\n",
        "    output = model(XL[ii, :])\n",
        "    loss = F.nll_loss(output, YL[ii])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    nd += ii.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk8FSktmszZD"
      },
      "source": [
        "## テストする\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlPlcaC1H9Ty"
      },
      "source": [
        "datT = mn.getImage('T') / 255.0  #  [0, 255] => [0,1]\n",
        "labT = mn.getLabel('T')\n",
        "NT = datT.shape[0]\n",
        "XT = torch.from_numpy(datT.astype(np.float32)).to(device)\n",
        "YT = torch.from_numpy(labT).to(device)\n",
        "bindexT = makeBatchIndex(NT, batchsize)\n",
        "\n",
        "model.eval()  # setting the module in evaluation mode\n",
        "lossT, accT = evaluate(model, XT, YT, bindexT)\n",
        "print('{:.4f} {:.2f}'.format(lossT, accT*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50H_Ty5DJvPT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}