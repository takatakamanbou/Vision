{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2LNuwGaUKRIMidWjY5v9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/Vision/blob/main/Vision2023_report02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZcF12ojSrJ"
      },
      "source": [
        "# Vision2023-report02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrIIY0RtpBYO"
      },
      "source": [
        "課題の期限や提出の方法などについては，別途お知らせしています\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSx7Ng2FkdUB"
      },
      "source": [
        "---\n",
        "## 準備\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### GPUを利用するようにランタイムのタイプを変更する\n"
      ],
      "metadata": {
        "id": "3xaSo__5tMel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "この notebook では，通常の Colab Notebook の動かし方では時間がかかる所があります．次のようにしてランタイムのタイプを変更し，より高速な計算ができるようにしましょう．\n",
        "\n",
        "1. メニューの「ランタイム」 > 「ランタイムのタイプを変更」 を選択．\n",
        "1. 「ノートブックの設定」というポップアップウィンドウが開くので，「ハードウェアアクセラレータ」を「None」から「GPU」に変更し，「保存」する\n",
        "1. いつもどおりコードセルを実行する．すでに実行していた場合，「以前のランタイムを削除する」というポップアップウィンドウが現れるので，「OK」を押しし，一番最初のコードセルから実行し直ます．\n",
        "\n",
        "Colab Notebook は Linux を OS とする PC （クラウド上の仮想マシン）で実行されます．\n",
        "通常は，その実行は CPU 上で行われますが，上記のように設定を変更することで，一部の計算を GPU にまかせることができるようになります（注）．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 無料でできますが，計算時間等が制限されています．\n",
        "</span>\n",
        "\n",
        "GPU (Graphical Processing Unit) というのは，PCのグラフィックスボード／ビデオカードやゲーム機等に搭載される，画像処理に特化した演算装置です．CPUのような汎用性がない代わりに，特定の処理をCPUよりずっと高速に実行できます．\n",
        "この notebook では PyTorch という深層学習フレームワークを使用しますが， PyTorch ではニューラルネットの出力や学習のための計算を GPU 上で行って高速化することが簡単にできるようになっています．"
      ],
      "metadata": {
        "id": "DHWsvGROH9y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### いろいろ import"
      ],
      "metadata": {
        "id": "b52pSlrFynUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 関係のほげ\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import FashionMNIST\n",
        "import torchsummary\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "hqKwr1oJD4mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU が使えるようになっていれば，↑のセルを実行すると `cuda:0` と出力されるはずです．\n"
      ],
      "metadata": {
        "id": "lmSbyUjm1MSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### データの準備\n",
        "\n",
        "このレポート課題では，FashionMNIST という画像データセットを用いた識別の実験を行います．このデータセットは，28x28画素のグレイスケール画像10種類から成ります．"
      ],
      "metadata": {
        "id": "HmMXKzOJMDrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データ読み込みの仕組み\n",
        "dsL = FashionMNIST(root='.', train=True, download=True, transform=ToTensor())\n",
        "dsT = FashionMNIST(root='.', train=False, download=True, transform=ToTensor())\n",
        "dlL = DataLoader(dsL, batch_size=100, shuffle=True)\n",
        "dlT = DataLoader(dsT, batch_size=100, shuffle=False)\n",
        "print(f'学習データ数: {len(dsL)}  テストデータ数: {len(dsT)}')\n",
        "\n",
        "# クラス番号とクラス名\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}"
      ],
      "metadata": {
        "id": "jX3Cnc-sMH1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 一部データを可視化\n",
        "nrow, ncol = 4, 5\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for i in range(nrow*ncol):\n",
        "    X, y = dsL[i]\n",
        "    fig.add_subplot(nrow, ncol, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X.squeeze(), cmap='gray')\n",
        "    plt.title(labels_map[y])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PqjXWKvLMkGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 学習に用いるクラス・関数の定義\n",
        "\n",
        "次の2つの関数は修正の必要はありません．"
      ],
      "metadata": {
        "id": "1On0a7yRMzCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1epoch の学習を行う関数\n",
        "#\n",
        "def train(model, lossFunc, optimizer, dl):\n",
        "    loss_sum = 0.0\n",
        "    ncorrect = 0\n",
        "    n = 0\n",
        "    for i, (X, lab) in enumerate(dl):\n",
        "        X, lab = X.to(device), lab.to(device)\n",
        "        Y = model(X)           # 一つのバッチ X を入力して出力 Y を計算\n",
        "        loss = lossFunc(Y, lab) # 正解ラベル lab に対する loss を計算\n",
        "        optimizer.zero_grad()   # 勾配をリセット\n",
        "        loss.backward()         # 誤差逆伝播でパラメータ更新量を計算\n",
        "        optimizer.step()         # パラメータを更新\n",
        "        n += len(X)\n",
        "        loss_sum += loss.item()  # 損失関数の値\n",
        "        ncorrect += (Y.argmax(dim=1) == lab).sum().item()  # 正解数\n",
        "\n",
        "    return loss_sum/n, ncorrect/n"
      ],
      "metadata": {
        "id": "oS_XSzRuNP2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失関数や識別率の値を求める関数\n",
        "#\n",
        "@torch.no_grad()\n",
        "def evaluate(model, lossFunc, dl):\n",
        "    loss_sum = 0.0\n",
        "    ncorrect = 0\n",
        "    n = 0\n",
        "    for i, (X, lab) in enumerate(dl):\n",
        "        X, lab = X.to(device), lab.to(device)\n",
        "        Y = model(X)           # 一つのバッチ X を入力して出力 Y を計算\n",
        "        loss = lossFunc(Y, lab)  # 正解ラベル lab に対する loss を計算\n",
        "        n += len(X)\n",
        "        loss_sum += loss.item() # 損失関数の値\n",
        "        ncorrect += (Y.argmax(dim=1) == lab).sum().item()  # 正解数\n",
        "\n",
        "    return loss_sum/n, ncorrect/n"
      ],
      "metadata": {
        "id": "-HhUlRENNVPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 問題1 ロジスティック回帰\n",
        "\n",
        "FashionMNIST のデータをロジスティック回帰で識別する実験を行いましょう．\n",
        "コードセルを順にそのまま実行してみてください．\n"
      ],
      "metadata": {
        "id": "jbRiAUK0rUS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ロジスティック回帰モデルを定義するクラス\n",
        "#\n",
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "    # コンストラクタ． D: 入力次元数， K: クラス数\n",
        "    def __init__(self, D, K):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 4次元テンソルで与えられる入力を2次元にする変換\n",
        "        self.fc = nn.Linear(D, K)  # 入力 => 出力層\n",
        "\n",
        "    # モデルの出力を計算するメソッド\n",
        "    def forward(self, X):\n",
        "        X = self.flatten(X)\n",
        "        X = self.fc(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "impMC44WNsPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習の実行 #####\n",
        "\n",
        "# ネットワークモデル\n",
        "net = LogisticRegression(784, 10).to(device)\n",
        "#torchsummary.summary(net, (1, 28, 28))\n",
        "print(net)\n",
        "\n",
        "# 損失関数（交差エントロピー）\n",
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "# パラメータ最適化器\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "# 学習の繰り返し回数\n",
        "nepoch = 20\n",
        "\n",
        "# 学習\n",
        "results = []\n",
        "print('# epoch  lossL  lossT  rateL  rateT')\n",
        "for t in range(1, nepoch+1):\n",
        "    lossL, rateL = train(net, loss_func, optimizer, dlL)\n",
        "    lossT, rateT = evaluate(net, loss_func, dlT)\n",
        "    results.append([t, lossL, lossT, rateL, rateT])\n",
        "    print(f'{t}   {lossL:.5f}   {lossT:.5f}   {rateL:.4f}   {rateT:.4f}')\n"
      ],
      "metadata": {
        "id": "DzplXZFQOisR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の\n",
        "```\n",
        "# epoch  lossL  lossT  rateL  rateT\n",
        "```\n",
        "の下の値は，左から順に学習繰り返し回数（エポック単位），学習データに対する損失関数の値，テストデータに対する同，学習データの識別率，テストデータに対する同，です．"
      ],
      "metadata": {
        "id": "Janc8VVXQtJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習結果の表示 #####\n",
        "\n",
        "# 学習曲線の表示\n",
        "data = np.array(results)\n",
        "fig, ax = plt.subplots(1, 2, facecolor='white', figsize=(12, 4))\n",
        "ax[0].plot(data[:, 0], data[:, 1], '.-', label='training data')\n",
        "ax[0].plot(data[:, 0], data[:, 2], '.-', label='test data')\n",
        "ax[0].axhline(0.0, color='gray')\n",
        "ax[0].set_ylim(-0.05, 0.5)\n",
        "ax[0].legend()\n",
        "ax[0].set_title(f'loss')\n",
        "ax[1].plot(data[:, 0], data[:, 3], '.-', label='training data')\n",
        "ax[1].plot(data[:, 0], data[:, 4], '.-', label='test data')\n",
        "ax[1].axhline(1.0, color='gray')\n",
        "ax[1].set_ylim(0.8, 1.01)\n",
        "ax[1].legend()\n",
        "ax[1].set_title(f'accuracy')\n",
        "plt.show()\n",
        "\n",
        "# 学習後の損失と識別率\n",
        "loss2, rrate = evaluate(net, loss_func, dlL)\n",
        "print(f'# 学習データに対する損失: {loss2:.5f}  識別率: {rrate:.4f}')\n",
        "loss2, rrate = evaluate(net, loss_func, dlT)\n",
        "print(f'# テストデータに対する損失: {loss2:.5f}  識別率: {rrate:.4f}')"
      ],
      "metadata": {
        "id": "n8t_p2wEP3cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルを実行して得られる2つのグラフを保存しておきましょう（右クリック → 名前をつけて画像を保存）．また，最後に出力される\n",
        "```\n",
        "# 学習データに対する損失: ...  識別率: ...\n",
        "# テストデータに対する損失: ...  識別率: ...\n",
        "```\n",
        "の部分をコピペして保存しておきましょう．\n",
        "\n",
        "パラメータの初期値が変われば結果も変わりますので，何度か実行し直してみるとよいでしょう．"
      ],
      "metadata": {
        "id": "8wY3bpnywqfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 問題2 2層ニューラルネット\n",
        "\n",
        "隠れ層を1つだけ持つニューラルネットで問題1と同じ実験を行いましょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "GKazxqnzWC6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2層ニューラルネットを定義するクラス\n",
        "#\n",
        "class MLP2(nn.Module):\n",
        "\n",
        "    # コンストラクタ． D: 入力次元数， H: 隠れ層ニューロン数， K: クラス数\n",
        "    def __init__(self, D, H, K):\n",
        "        super(MLP2, self).__init__()\n",
        "        # 4次元テンソルで与えられる入力を2次元にする変換\n",
        "        self.flatten = nn.Flatten()\n",
        "        # 入力 => 隠れ層\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(D, H), nn.ReLU()\n",
        "        )\n",
        "        # 隠れ層 => 出力層\n",
        "        self.fc2 = nn.Linear(H, K) # 出力層には活性化関数を指定しない\n",
        "\n",
        "    # モデルの出力を計算するメソッド\n",
        "    def forward(self, X):\n",
        "        X = self.flatten(X)\n",
        "        X = self.fc1(X)\n",
        "        X = self.fc2(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "rrbeHOkXWL26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "↑のセルは実行するだけです．修正の必要はありません．\n",
        "\n",
        "次のコードセルに，問題1の\n",
        "```\n",
        "##### 学習の実行 #####\n",
        "```\n",
        "のセルをコピペして，\n",
        "```\n",
        "net = LogisticRegression(784, 10).to(device)\n",
        "```\n",
        "の行を\n",
        "```\n",
        "net = MLP2(784, ???, 10).to(device)\n",
        "```\n",
        "に修正して実行しましょう． `???` には自然数を指定します．\n",
        "`MLP2` クラスを定義しているコードセルの内容に基づいて，適当そうな値を選んでください．"
      ],
      "metadata": {
        "id": "hKTueA3kWsGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習の実行 #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HEf0YdmIXF1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルに，問題1の\n",
        "```\n",
        "##### 学習結果の表示 #####\n",
        "```\n",
        "のセルをコピペして実行しましょう．修正の必要はありません．"
      ],
      "metadata": {
        "id": "YOe-1aUIZhxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習結果の表示 #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ux0A3dJVZgl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`???` の値を何通りか試して，問題1と同様にグラフと結果の値を保存しておきましょう．"
      ],
      "metadata": {
        "id": "7BetMUQZXRev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 問題3 3層ニューラルネット\n",
        "\n",
        "隠れ層を2つ持つニューラルネットで問題1と同じ実験を行いましょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "xT0uMAe3cWeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3層ニューラルネットを定義するクラス\n",
        "#\n",
        "class MLP3(nn.Module):\n",
        "\n",
        "    # コンストラクタ． D: 入力次元数， H1, H2: 隠れ層ニューロン数， K: クラス数\n",
        "    def __init__(self, D, H1, H2, K):\n",
        "        super(MLP3, self).__init__()\n",
        "        # 4次元テンソルで与えられる入力を2次元にする変換\n",
        "        self.flatten = nn.Flatten()\n",
        "        # 入力 => 隠れ層1\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(D, H1), nn.ReLU()\n",
        "        )\n",
        "        ### 続きを自分で書いてね ###\n"
      ],
      "metadata": {
        "id": "mf8bBzHQaYu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のコードセルと，次の2つのコードセルの中身を書いて実験しましょう．\n",
        "ニューロン数は適当に選んでください．"
      ],
      "metadata": {
        "id": "3QlOwV_6eOSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習の実行 #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FSMwz4GieDS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習結果の表示 #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YB98w7xjeGOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ニューロン数を何通りか試して，問題1と同様にグラフと結果の値を保存しておきましょう．"
      ],
      "metadata": {
        "id": "pZRg3KcGehs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 問題4 畳み込みニューラルネット\n",
        "\n",
        "畳み込みニューラルネットで問題1と同じ実験を行いましょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "CExxYqIfe2Jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 畳み込みニューラルネットの構造は適当に自分で定めてください．他人のコードを参考にするのは構いませんが，理解せずに使うことはやめましょう．\n",
        "- ネットワークを定義するクラスの名前は次の通り `CNN` としてください．コンストラクタの引数の設定などは任意です．"
      ],
      "metadata": {
        "id": "NHyjkT-6f6pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 畳み込みニューラルネットを定義するクラス\n",
        "#\n",
        "class CNN(nn.Module):\n",
        "    "
      ],
      "metadata": {
        "id": "xzJ-pIkZell2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習の実行 #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HJ9cOOqOieOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 学習結果の表示 #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vgpj3YWgieOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 問題5 レポートにまとめる\n",
        "\n",
        "今回は，次の二つのものを作成して提出してもらいます． \n",
        "\n",
        "1. この notebook を編集したもの\n",
        "1. 実験結果の図や数値をまとめ，考察を記した文書\n",
        "\n",
        "2.の方は，この授業の個別共有フォルダを開いた状態で，左上の「+ 新規」を押すか右クリックして「Google ドキュメント」を選択し，そこに書き込む形としてください．\n",
        "\n",
        "実験1から実験4までの図や数値を整理してまとめ，それらに対する考察を行ってください．\n"
      ],
      "metadata": {
        "id": "BUMwuchdj5or"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S7R9K_OlilJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}