{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/Vision/blob/main/Vision2023_ex14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# Vision2023-ex14\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 準備\n",
        "---"
      ],
      "metadata": {
        "id": "77cUTDP53mnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPUを利用するようにランタイムのタイプを変更する\n"
      ],
      "metadata": {
        "id": "3xaSo__5tMel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "この notebook では，通常の Colab Notebook の動かし方では時間がかかる所があります（特に最後の実験）．次のようにしてランタイムのタイプを変更し，より高速な計算ができるようにしましょう．\n",
        "\n",
        "1. メニューの「ランタイム」 > 「ランタイムのタイプを変更」 を選択．\n",
        "1. 「ノートブックの設定」というポップアップウィンドウが開くので，「ハードウェアアクセラレータ」を「None」から「GPU」に変更し，「保存」する\n",
        "1. いつもどおりコードセルを実行する．すでに実行していた場合，「以前のランタイムを削除する」というポップアップウィンドウが現れるので，「OK」を押しし，一番最初のコードセルから実行し直ます．\n",
        "\n",
        "Colab Notebook は Linux を OS とする PC （クラウド上の仮想マシン）で実行されます．\n",
        "通常は，その実行は CPU 上で行われますが，上記のように設定を変更することで，一部の計算を GPU にまかせることができるようになります（注）．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 無料でできますが，計算時間等が制限されています．\n",
        "</span>\n",
        "\n",
        "GPU (Graphical Processing Unit) というのは，PCのグラフィックスボード／ビデオカードやゲーム機等に搭載される，画像処理に特化した演算装置です．CPUのような汎用性がない代わりに，特定の処理をCPUよりずっと高速に実行できます．\n",
        "この notebook では PyTorch という深層学習フレームワークを使用しますが， PyTorch ではニューラルネットの出力や学習のための計算を GPU 上で行って高速化することが簡単にできるようになっています．"
      ],
      "metadata": {
        "id": "DHWsvGROH9y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### いろいろ import"
      ],
      "metadata": {
        "id": "b52pSlrFynUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBTXo5eHh34P"
      },
      "outputs": [],
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 関係のほげ\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchsummary\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "hqKwr1oJD4mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU が使えるようになっていれば，↑のセルを実行すると `cuda:0` と出力されるはずです．\n"
      ],
      "metadata": {
        "id": "lmSbyUjm1MSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 手書き数字データの入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/minimnist.npz\n",
        "minimnist = np.load('minimnist.npz')\n",
        "K = 10 # クラス数\n",
        "D = minimnist['datL'].shape[1] # データの次元数 28 x 28 = 784"
      ],
      "metadata": {
        "id": "17p1fbo5EhsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データを画像として表示するための関数\n",
        "#\n",
        "def display(data, nx, ny, nrow=28, ncol=28, gap=4):\n",
        "\n",
        "    assert data.shape[1] == nrow*ncol\n",
        "\n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype = int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        for ix in range(nx):\n",
        "            if iy*nx+ix < data.shape[0]:\n",
        "                ltx = ix*(ncol + gap) + gap\n",
        "                img[lty:lty+nrow, ltx:ltx+ncol] = data[iy*nx+ix].reshape((nrow, ncol))\n",
        "\n",
        "    # 画像の出力\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "m3fSfpOe4N5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx, ny = 10, 10\n",
        "display(minimnist['datL'], nx, ny)"
      ],
      "metadata": {
        "id": "ugAZFgI-6XE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 主成分分析による次元削減と再構成\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9kq8MMK34dyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画素値を 255 で割って平均を引いたものをデータとする\n",
        "XL = minimnist['datL'].astype(float) / 255\n",
        "XT = minimnist['datT'].astype(float) / 255\n",
        "Xmean = np.mean(XL, axis=0)\n",
        "XL -= Xmean\n",
        "XT -= Xmean\n",
        "print(XL.shape, XT.shape)\n",
        "\n",
        "# 平均を画像として表示\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.axis('off')\n",
        "plt.imshow(Xmean.reshape(28, 28)*255, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2m9TZxjL5qDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XL の分散共分散行列の固有値と固有ベクトルを求める\n",
        "_, sv, Vt = np.linalg.svd(XL, full_matrices=False)\n",
        "eva = sv**2/len(XL)\n",
        "U = Vt\n",
        "print(eva.shape, U.shape)\n",
        "\n",
        "# 累積寄与率を求める\n",
        "cumcontrib = np.cumsum(eva)\n",
        "cumcontrib /= cumcontrib[-1]"
      ],
      "metadata": {
        "id": "LARj1JeW6wq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 固有値と固有ベクトルを図示\n",
        "plt.figure(figsize=(6, 3))\n",
        "fig, ax = plt.subplots(1, 2, facecolor='white', figsize=(12, 4))\n",
        "Dmax = 100\n",
        "ax[0].plot(np.arange(1, Dmax+1), eva[:Dmax], '.-', label='eigenvalues')\n",
        "ax[0].legend()\n",
        "Dmax = 200\n",
        "ax[1].plot(np.arange(1, Dmax+1), cumcontrib[:Dmax], '-', label='cumrative contribution rate')\n",
        "ax[1].legend()\n",
        "ax[1].axhline(0.8, color='gray')\n",
        "ax[1].axhline(0.9, color='gray')\n",
        "ax[1].axhline(0.95, color='gray')\n",
        "ax[1].set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X_ANKkWM7PGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 再構成して誤差を求める\n",
        "hdimList = [10, 20, 50, 100, 200, 500]\n",
        "sqeL = np.empty(len(hdimList))\n",
        "sqeT = np.empty_like(sqeL)\n",
        "\n",
        "YL = XL @ U.T\n",
        "YT = XT @ U.T\n",
        "print(f'hdim    sqeL    sqeT')\n",
        "for i, hdim in enumerate(hdimList):\n",
        "    ZL = YL[:, :hdim] @ U[:hdim, :]\n",
        "    ZT = YT[:, :hdim] @ U[:hdim, :]\n",
        "    sqeL[i] = np.mean((XL - ZL)**2)\n",
        "    sqeT[i] = np.mean((XT - ZT)**2)\n",
        "    print(f'{hdim}   {sqeL[i]:.6f}    {sqeT[i]:.6f}')\n"
      ],
      "metadata": {
        "id": "qX2hy2jC8rNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 次元数を決めて再構成画像をつくる\n",
        "hdim = 50\n",
        "YT = XT @ U[:hdim, :].T\n",
        "ZT = YT @ U[:hdim, :]\n",
        "img = (ZT + Xmean) * 255\n",
        "img = np.clip(img, 0, 255)\n",
        "\n",
        "nx, ny = 10, 4\n",
        "display(minimnist['datT'], nx, ny) # 元画像\n",
        "display(img, nx, ny) # 再構成"
      ],
      "metadata": {
        "id": "gWN9gcSCBMsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 全結合型 Auto-Encoder による次元削減と再構成\n",
        "---"
      ],
      "metadata": {
        "id": "DaZ3iAhPAcVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "JFWbAlc9FCU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを扱うためのクラス\n",
        "#\n",
        "class MMDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, LT):\n",
        "        self.XL = data['datL'].astype(float)/255\n",
        "        self.XT = data['datT'].astype(float)/255\n",
        "        self.Xmean = np.mean(self.XL, axis=0)\n",
        "        self.XL -= self.Xmean\n",
        "        self.XT -= self.Xmean\n",
        "        if LT == 'L':\n",
        "            self.X = self.XL\n",
        "            self.Y = data['labL']\n",
        "        else:\n",
        "            self.X = self.XT\n",
        "            self.Y = data['labT']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.Y[idx], dtype=torch.int64)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "jNE6A2dV_qUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2層のオートエンコーダ（線形）\n",
        "#\n",
        "class AutoEncoder2(nn.Module):\n",
        "\n",
        "    def __init__(self, D, H):\n",
        "        super(AutoEncoder2, self).__init__()\n",
        "        L = []\n",
        "        # エンコーダ部\n",
        "        L.append(nn.Linear(D, H, bias=False))\n",
        "        # デコーダ部\n",
        "        L.append(nn.Linear(H, D, bias=False))\n",
        "        self.layers = nn.ModuleList(L)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "FXZi03V9AxWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4層のオートエンコーダ（非線形）\n",
        "#\n",
        "class AutoEncoder4(nn.Module):\n",
        "\n",
        "    def __init__(self, D, M, H):\n",
        "        super(AutoEncoder4, self).__init__()\n",
        "        L = []\n",
        "        # エンコーダ部\n",
        "        L.append(nn.Linear(D, M))\n",
        "        L.append(nn.ReLU())\n",
        "        L.append(nn.Linear(M, H, bias=False))\n",
        "        # デコーダ部\n",
        "        L.append(nn.Linear(H, M))\n",
        "        L.append(nn.ReLU())\n",
        "        L.append(nn.Linear(M, D))\n",
        "        self.layers = nn.ModuleList(L)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "Tk3g0DBXDo4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習の関数\n",
        "#\n",
        "def train(model, lossFunc, optimizer, dl):\n",
        "    loss_sum = 0.0\n",
        "    n = 0\n",
        "    for i, (X, lab) in enumerate(dl):\n",
        "        X, lab = X.to(device), lab.to(device)\n",
        "        Z = model(X)           # 一つのバッチ X を入力して出力 Z を計算\n",
        "        loss = lossFunc(Z, X)  # 入力と出力の間の誤差を計算\n",
        "        optimizer.zero_grad()  # 勾配をリセット\n",
        "        loss.backward()        # 誤差逆伝播でパラメータ更新量を計算\n",
        "        optimizer.step()       # パラメータを更新\n",
        "        n += len(X)\n",
        "        loss_sum += loss.item()  # 損失関数の値\n",
        "\n",
        "    return loss_sum/n"
      ],
      "metadata": {
        "id": "oBNhjWq_EOci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価の関数\n",
        "#\n",
        "@torch.no_grad()\n",
        "def evaluate(model, lossFunc, dl):\n",
        "    loss_sum = 0.0\n",
        "    n = 0\n",
        "    for i, (X, lab) in enumerate(dl):\n",
        "        X, lab = X.to(device), lab.to(device)\n",
        "        Z = model(X)           # 一つのバッチ X を入力して出力 Y を計算\n",
        "        loss = lossFunc(Z, X)  # 入力と出力の間の誤差を計算\n",
        "        n += len(X)\n",
        "        loss_sum += loss.item() # 損失関数の値\n",
        "\n",
        "    return loss_sum/n"
      ],
      "metadata": {
        "id": "59vMie3pEwGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験その1 2層 Auto-Encoder"
      ],
      "metadata": {
        "id": "mxzNYDYrFExl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データ読み込みの仕組み\n",
        "dsL = MMDataset(minimnist, 'L')\n",
        "dsT = MMDataset(minimnist, 'T')\n",
        "dlL = DataLoader(dsL, batch_size=100, shuffle=False)\n",
        "dlT = DataLoader(dsT, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークモデルの定義\n",
        "H = 10\n",
        "net = AutoEncoder2(D, H).to(device)\n",
        "\n",
        "# 損失関数（二乗誤差）\n",
        "loss_func = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# パラメータ最適化器\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "# 学習の繰り返し回数\n",
        "nepoch = 100\n",
        "\n",
        "# 学習\n",
        "L = []\n",
        "print('########## 実験1 ##########');\n",
        "print(f'学習データ数: {len(dsL)}  テストデータ数: {len(dsT)}')\n",
        "print()\n",
        "print(net)\n",
        "print()\n",
        "print('# epoch  msqeL  msqeT')\n",
        "for t in range(1, nepoch+1):\n",
        "    msqeL = train(net, loss_func, optimizer, dlL) / D\n",
        "    msqeT = evaluate(net, loss_func, dlT) / D\n",
        "    L.append([t, msqeL, msqeT])\n",
        "    if (t < 10) or (t % 10 == 0):\n",
        "        print(f'{t}   {msqeL:.6f}   {msqeT:.6f}')\n"
      ],
      "metadata": {
        "id": "scYUorv6FAJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 実験その2 4層 Auto-Encoder"
      ],
      "metadata": {
        "id": "ktlyZLe3G4oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データ読み込みの仕組み\n",
        "dsL = MMDataset(minimnist, 'L')\n",
        "dsT = MMDataset(minimnist, 'T')\n",
        "dlL = DataLoader(dsL, batch_size=100, shuffle=False)\n",
        "dlT = DataLoader(dsT, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークモデルの定義\n",
        "M = 1000\n",
        "H = 10\n",
        "net = AutoEncoder4(D, M, H).to(device)\n",
        "\n",
        "# 損失関数（二乗誤差）\n",
        "loss_func = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# パラメータ最適化器\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "# 学習の繰り返し回数\n",
        "nepoch = 100\n",
        "\n",
        "# 学習\n",
        "L = []\n",
        "print('########## 実験2 ##########');\n",
        "print(f'学習データ数: {len(dsL)}  テストデータ数: {len(dsT)}')\n",
        "print()\n",
        "print(net)\n",
        "print()\n",
        "print('# epoch  msqeL  msqeT')\n",
        "for t in range(1, nepoch+1):\n",
        "    msqeL = train(net, loss_func, optimizer, dlL) / D\n",
        "    msqeT = evaluate(net, loss_func, dlT) / D\n",
        "    L.append([t, msqeL, msqeT])\n",
        "    if (t < 10) or (t % 10 == 0):\n",
        "        print(f'{t}   {msqeL:.6f}   {msqeT:.6f}')\n"
      ],
      "metadata": {
        "id": "ZU-f4ST3G34I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データの再構成を求める\n",
        "for X, lab in dlL:\n",
        "    X, lab = X.to(device), lab.to(device)\n",
        "    Z = net(X)\n",
        "    break\n",
        "img = (Z.cpu().detach().numpy() + Xmean) * 255\n",
        "img = np.clip(img, 0, 255)\n",
        "\n",
        "nx, ny = 10, 4\n",
        "display(minimnist['datL'], nx, ny) # 元画像\n",
        "display(img, nx, ny) # 再構成"
      ],
      "metadata": {
        "id": "otGqrvRWIDOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータの再構成を求める\n",
        "for X, lab in dlT:\n",
        "    X, lab = X.to(device), lab.to(device)\n",
        "    Z = net(X)\n",
        "    break\n",
        "img = (Z.cpu().detach().numpy() + Xmean) * 255\n",
        "img = np.clip(img, 0, 255)\n",
        "\n",
        "nx, ny = 10, 4\n",
        "display(minimnist['datT'], nx, ny) # 元画像\n",
        "display(img, nx, ny) # 再構成"
      ],
      "metadata": {
        "id": "rInMY5pQFkNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SBkAmvzmHkjt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}